@page "/web-rtc"
@rendermode InteractiveServer
@using System.Text.Json
@using BlazorVoice.Akka
@using BlazorVoice.Akka.Actor
@using global::Akka.Actor
@inject BlazorVoice.Services.OpenAIService OpenAIService
@inject IJSRuntime JSRuntime
@inject AkkaService AkkaService
@inject IServiceProvider ServiceProvider

<PageTitle>AIVoiceChat</PageTitle>

<h1>AIVoiceChat</h1>

<MudGrid>

    <!-- Player -->
    <MudItem xs="6">
        <!-- AI Ani -->
        <MudPaper Class="d-flex align-center justify-center mud-width-full py-8">
            <canvas id="aiFaceCanvas" width="320" height="240" style="position: left: 0; top: 0; width: 50%; height: 50%; pointer-events: none;"></canvas>
        </MudPaper>
    </MudItem>
    <MudItem xs="6">
        <!-- Video -->
        <MudPaper Class="d-flex align-center justify-center mud-width-full py-8">
            <video id="localVideo" autoplay muted style="width: 50%; border-radius: 8px;"></video>
        </MudPaper>
    </MudItem>

    <!-- 채팅창 -->
    <MudItem xs="12">
        <MudPaper Class="pa-3">
            <MudButton OnClick="StartWebRTC" Class="mt-4">
                Start WebRTC
            </MudButton>
        </MudPaper>
        <MudPaper Class="pa-3">
            <MudText Typo="Typo.subtitle1">채팅</MudText>
            <MudStack>
                <!-- 채팅 리스트 -->
                <MudList T="string">
                    @foreach (var chat in ChatMessages)
                    {
                        <MudListItem Text="@chat" Icon="@Icons.Material.Filled.Chat" />
                    }
                </MudList>
                <!-- 채팅 입력 -->
                <MudTextField @bind-Value="ChatInput" Placeholder="메시지를 입력하세요..."
                               />

                <MudButton OnClick="SendChatMessage" Class="mt-2">전송</MudButton>
            </MudStack>
        </MudPaper>
    </MudItem>


    <!-- Audio -->
    <MudItem xs="12">
        <MudStack>
            <MudPaper Class="pa-3">
                <MudText Typo="Typo.subtitle1" Class="mt-4">오디오바</MudText>
                <MudProgressLinear Value="@AudioLevel" Class="mt-2" />
            </MudPaper>
            <MudPaper Class="pa-3">
                <MudText Typo="Typo.subtitle1" Class="mt-4">마이크 볼륨 조절</MudText>
                <MudSlider @bind-Value="MicrophoneVolume" Min="0" Max="100" Step="1" Class="mt-2" />
            </MudPaper>
        </MudStack>

    </MudItem>
</MudGrid>


@code {

    private double AudioLevel { get; set; } = 0;
    private double MicrophoneVolume { get; set; } = 10; // 초기 볼륨 값
    private string ChatInput { get; set; } = string.Empty;
    private List<string> ChatMessages { get; set; } = new();
    private string SelectedChatOption { get; set; } = "EchoTTS";
    private string UserId { get; set; } = string.Empty;

    private IActorRef MyVoiceActor { get; set; } = null!;

    protected override async Task OnInitializedAsync()
    {
        // JavaScript를 호출하여 유니크 ID를 가져옴
        UserId = await JSRuntime.InvokeAsync<string>("getOrCreateUniqueId");
        Console.WriteLine($"User ID: {UserId}");

        string voiceChatActorKey = $"VoiceChatActor-{UserId}";

        var actorSystem = AkkaService.GetActorSystem();

        var voiceCahtActor = AkkaService.GetActor(voiceChatActorKey);        

        if(voiceCahtActor==null)
        {
            // VoiceChatActor가 없으면 생성 - 비식별 세션별단위로 생성
            voiceCahtActor = actorSystem.ActorOf(Props.Create(() => 
                new VoiceChatActor(ServiceProvider)), UserId);

            AkkaService.AddActor(voiceChatActorKey, voiceCahtActor);
        }

        // UX를 제어권인 대리자 생성해 전달        
        voiceCahtActor.Tell(CreateDynamicDelegate());

        MyVoiceActor = voiceCahtActor;

    }

    private async Task StartWebRTC()
    {
        var dotNetRef = DotNetObjectReference.Create(this);
        await JSRuntime.InvokeVoidAsync("startWebRTC", "localVideo", "remoteVideo", dotNetRef);
    }


    [JSInvokable]
    public async Task SendAudioData(string audioDataJson)
    {
        try
        {
            // Parse JSON data
            var data = JsonSerializer.Deserialize<Dictionary<string, object>>(audioDataJson);
            if (data != null && data.ContainsKey("volume") && data.ContainsKey("audioData"))
            {
                // Validate volume
                if (data["volume"] is JsonElement volumeElement && volumeElement.TryGetDouble(out var volume))
                {
                    // Validate audioData
                    if (data["audioData"] is JsonElement audioDataElement && audioDataElement.ValueKind == JsonValueKind.Array)
                    {
                        var audioBytes = audioDataElement.EnumerateArray().Select(x => (byte)x.GetInt32()).ToArray();
                        // Update UI with volume
                        AudioLevel = Math.Clamp(volume, 0, 100);
                        StateHasChanged();
                        // Debugging output
                        //Console.WriteLine($"Valid audio data received. Volume: {volume}, Data size: {audioBytes.Length} bytes");
                        // Send audio data to SignalR server (if needed)
                        // await HubContext.Clients.All.SendAsync("SendAudioData", audioBytes);
                    }
                    else
                    {
                        Console.WriteLine("Invalid audioData format.");
                    }
                }
                else
                {
                    Console.WriteLine("Invalid volume format.");
                }
            }
            else
            {
                Console.WriteLine("Invalid audio data structure.");
            }
        }
        catch (Exception ex)
        {
            Console.WriteLine($"Error in SendAudioData: {ex.Message}");
        }
    }


    private async Task UpdateMicrophoneVolume()
    {
        await JSRuntime.InvokeVoidAsync("setMicrophoneVolume", MicrophoneVolume);
    }

    private async Task HandleChatInputKeyUp(KeyboardEventArgs e)
    {
        if (e.Key == "Enter")
        {
            await SendChatMessage();
        }
    }

    private async Task SendChatMessage()
    {
        if (!string.IsNullOrWhiteSpace(ChatInput))
        {
            await HandleTTS(ChatInput);

            ChatInput = string.Empty;            

        }
    }

    private async Task HandleTTS(string message)
    {
        MyVoiceActor.Tell(new TTSCommand()
        {
            From = "Your",
            Text = message,
            Voice = "coral"
        });        

        StateHasChanged(); // UI 업데이트
    }

    [JSInvokable]
    public async Task OnAudioPlaybackCompleted(int option)
    {
        MyVoiceActor.Tell(new TTSCommand()
        {
            From = "AI",
            Text = "LLM자동재생",
            Voice = "alloy"
        });
    }

    private void PlayAudioBytes(float[] voice, float speed, int playtype)
    {
        InvokeAsync(() =>
        {
            var dotNetRef = DotNetObjectReference.Create(this);
            JSRuntime.InvokeVoidAsync("playAudioBytes", voice, speed, playtype, dotNetRef);
        });
    }


    private void AddMessage(string from, string message)
    {
        InvokeAsync(() =>
        {
            ChatMessages.Add($"[{from}] {message} - {DateTime.Now:HH:mm:ss}");
            StateHasChanged(); // UI 업데이트
        });        
    }

    private Action<string, object[]> CreateDynamicDelegate()
    {
        return (methodName, args) =>
        {
            // Blazor 컴포넌트의 메서드 찾기
            var method = GetType().GetMethod(methodName, System.Reflection.BindingFlags.Instance | System.Reflection.BindingFlags.NonPublic | System.Reflection.BindingFlags.Public);
            if (method == null)
            {
                Console.WriteLine($"Method '{methodName}' not found.");
                return;
            }

            try
            {
                // 메서드 호출
                method.Invoke(this, args);
            }
            catch (Exception ex)
            {
                Console.WriteLine($"Error invoking method '{methodName}': {ex.Message}");
            }
        };
    }

}
