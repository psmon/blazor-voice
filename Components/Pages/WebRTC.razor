@page "/web-rtc"
@rendermode InteractiveServer
@using System.Text.Json
@using BlazorVoice.Akka
@using BlazorVoice.Akka.Actor
@using global::Akka.Actor
@inject BlazorVoice.Services.OpenAIService OpenAIService
@inject IJSRuntime JSRuntime
@inject AkkaService AkkaService
@inject IServiceProvider ServiceProvider

<PageTitle>WebRTC</PageTitle>

<h1>WebRTC</h1>

<MudGrid>
    <!-- 채팅창 -->
    <MudItem xs="12">
        <MudPaper Class="pa-3">
            <MudButton OnClick="StartWebRTC" Class="mt-4">
                Start WebRTC
            </MudButton>
        </MudPaper>
        <MudPaper Class="pa-3">
            <MudText Typo="Typo.subtitle1">채팅</MudText>
            <MudStack>
                <!-- 채팅 리스트 -->
                <MudList T="string">
                    @foreach (var chat in ChatMessages)
                    {
                        <MudListItem Text="@chat" Icon="@Icons.Material.Filled.Chat" />
                    }
                </MudList>
                <!-- 채팅 입력 -->
                <MudTextField @bind-Value="ChatInput" Placeholder="메시지를 입력하세요..." />
                <MudButton OnClick="SendChatMessage" Class="mt-2">전송</MudButton>
            </MudStack>
        </MudPaper>
    </MudItem>

    <!-- Video -->
    <MudItem xs="6">
        <MudPaper Class="d-flex align-center justify-center mud-width-full py-8">
            <video id="remoteVideo" autoplay style="width: 100%; border-radius: 8px;"></video>
        </MudPaper>
    </MudItem>
    <MudItem xs="6">
        <MudPaper Class="d-flex align-center justify-center mud-width-full py-8">
            <video id="localVideo" autoplay muted style="width: 50%; border-radius: 8px;"></video>
        </MudPaper>
    </MudItem>

    <!-- Audio -->
    <MudItem xs="12">
        <MudStack>
            <MudPaper Class="pa-3">
                <MudText Typo="Typo.subtitle1" Class="mt-4">오디오바</MudText>
                <MudProgressLinear Value="@AudioLevel" Class="mt-2" />
            </MudPaper>
            <MudPaper Class="pa-3">
                <MudText Typo="Typo.subtitle1" Class="mt-4">마이크 볼륨 조절</MudText>
                <MudSlider @bind-Value="MicrophoneVolume" Min="0" Max="100" Step="1" Class="mt-2" />
            </MudPaper>
        </MudStack>

    </MudItem>
</MudGrid>


@code {

    private double AudioLevel { get; set; } = 0;
    private double MicrophoneVolume { get; set; } = 10; // 초기 볼륨 값
    private string ChatInput { get; set; } = string.Empty;
    private List<string> ChatMessages { get; set; } = new();
    private string SelectedChatOption { get; set; } = "EchoTTS";
    private string UserId { get; set; } = string.Empty;

    private IActorRef MyVoiceActor { get; set; } = null!;

    protected override async Task OnInitializedAsync()
    {
        // JavaScript를 호출하여 유니크 ID를 가져옴
        UserId = await JSRuntime.InvokeAsync<string>("getOrCreateUniqueId");
        Console.WriteLine($"User ID: {UserId}");

        string voiceChatActorKey = $"VoiceChatActor-{UserId}";

        var voiceCahtActor = AkkaService.GetActor(voiceChatActorKey);

        var actorSystem = AkkaService.GetActorSystem();

        if(voiceCahtActor==null)
        {
            // VoiceChatActor가 없으면 생성
            voiceCahtActor = actorSystem.ActorOf(Props.Create(() => 
                new VoiceChatActor(ServiceProvider)), UserId);

            AkkaService.AddActor(voiceChatActorKey, voiceCahtActor);
        }
    }

    private async Task StartWebRTC()
    {
        var dotNetRef = DotNetObjectReference.Create(this);
        await JSRuntime.InvokeVoidAsync("startWebRTC", "localVideo", "remoteVideo", dotNetRef);
    }


    [JSInvokable]
    public async Task SendAudioData(string audioDataJson)
    {
        try
        {
            // Parse JSON data
            var data = JsonSerializer.Deserialize<Dictionary<string, object>>(audioDataJson);
            if (data != null && data.ContainsKey("volume") && data.ContainsKey("audioData"))
            {
                // Validate volume
                if (data["volume"] is JsonElement volumeElement && volumeElement.TryGetDouble(out var volume))
                {
                    // Validate audioData
                    if (data["audioData"] is JsonElement audioDataElement && audioDataElement.ValueKind == JsonValueKind.Array)
                    {
                        var audioBytes = audioDataElement.EnumerateArray().Select(x => (byte)x.GetInt32()).ToArray();
                        // Update UI with volume
                        AudioLevel = Math.Clamp(volume, 0, 100);
                        StateHasChanged();
                        // Debugging output
                        //Console.WriteLine($"Valid audio data received. Volume: {volume}, Data size: {audioBytes.Length} bytes");
                        // Send audio data to SignalR server (if needed)
                        // await HubContext.Clients.All.SendAsync("SendAudioData", audioBytes);
                    }
                    else
                    {
                        Console.WriteLine("Invalid audioData format.");
                    }
                }
                else
                {
                    Console.WriteLine("Invalid volume format.");
                }
            }
            else
            {
                Console.WriteLine("Invalid audio data structure.");
            }
        }
        catch (Exception ex)
        {
            Console.WriteLine($"Error in SendAudioData: {ex.Message}");
        }
    }

    [JSInvokable]
    public async Task OnAudioPlaybackCompleted(int option)
    {
        Console.WriteLine("Blazor에서 오디오 재생 완료 이벤트 처리");
        // 추가 작업 수행 가능

        var msg = OpenAIService.GetLastAiMessage();        
        AddMessage("AI", msg);

        var recVoice = await OpenAIService.ConvertTextToVoiceAsync(msg); // TTS 처리

        var dotNetRef = DotNetObjectReference.Create(this);
        await JSRuntime.InvokeVoidAsync("playAudioBytes", recVoice, 0.5f, 2, dotNetRef);

        StateHasChanged(); // UI 업데이트
    }

    private async Task UpdateMicrophoneVolume()
    {
        await JSRuntime.InvokeVoidAsync("setMicrophoneVolume", MicrophoneVolume);
    }

    private async Task SendChatMessage()
    {
        if (!string.IsNullOrWhiteSpace(ChatInput))
        {
            //ChatMessages.Add($"[{SelectedChatOption}] {ChatInput}");

            if (SelectedChatOption == "EchoTTS")
            {
                await HandleEchoTTS(ChatInput);
            }
            else if (SelectedChatOption == "TTS to LLM")
            {
                await HandleTTSToLLM(ChatInput);
            }

            ChatInput = string.Empty;
        }
    }

    private async Task HandleEchoTTS(string message)
    {
        // EchoTTS 처리 로직
        //await JSRuntime.InvokeVoidAsync("playTextAsSpeech", message);        
        AddMessage("Human", message);

        var dotNetRef = DotNetObjectReference.Create(this);
        var recVoice = await OpenAIService.ConvertTextToVoiceWithLLMAsync(message); // TTS 처리

        await JSRuntime.InvokeVoidAsync("playAudioBytes", recVoice, 0.5f, 1, dotNetRef);

        StateHasChanged(); // UI 업데이트

    }

    private async Task HandleTTSToLLM(string message)
    {
        // TTS to LLM 처리 로직
        //var response = await OpenAIService.GetResponseFromLLM(message);
        AddMessage("AI", message);
    }

    private void AddMessage(string from, string message)
    {
        ChatMessages.Add($"[{from}] {message} - {DateTime.Now.ToString("HH:mm:ss")}");
    }

}
